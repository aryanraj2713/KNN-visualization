# KNN-visualization
K-Nearest Neighbors Algorithm is one of the simple, easy-to-implement, and yet effective supervised machine learning algorithms. It is called a lazy learner algorithm because it does not learn from the training set immediately instead it stores the dataset and at the time of classification, it performs an action on the datase
![KNN-1](https://user-images.githubusercontent.com/75358720/161425446-e086dc39-4683-4590-b6cb-9a96466bd589.gif)


## It's advantages-
- [ ] No Training Period: KNN is called Lazy Learner (Instance based learning). It does not learn anything in the training period. It does not derive any discriminative function from the training data.
- [ ] Since the KNN algorithm requires no training before making predictions, new data can be added seamlessly which will not impact the accuracy of the algorithm.
- [ ] KNN is very easy to implement. There are only two parameters required to implement KNN i.e. the value of K and the distance function.

Here we will be using Euclidean distance to calculate the distance of a new data point from each point in our training dataset

![image](https://user-images.githubusercontent.com/75358720/161425405-8013f898-90e9-470f-9be8-41f5ffb81dc1.png)



   <img src="https://img.shields.io/badge/Author-Aryan%20Raj-brightgreen" height="28"/><br>






